\chapter{Benchmark Design}
We developed a tool, called StreamBench, to execute benchmark workloads on stream processing systems. A key feature of StreamBench is extensibility, so that it could be extended not only to run new workloads but also to benchmark new stream processing systems. We have used StreamBench to measure the performance of several stream processing systems, as we report in the next chapter.  StreamBench is also available under an open source license, so that others may use and extend it, and contribute new workloads and stream processing system interfaces.

In this chapter, we describe the architecture of StreamBench and introduce more detail of main components of StreamBench. 

\section{Architecture}

\begin{figure}
  \begin{center}
  \subfigure{\includegraphics[scale=0.6]{images/benchmark_architecture}}
   \caption{StreamBench architecture}
   \label{fig:streambench_architecture}
  \end{center}
\end{figure}

The main component of StreamBench is a Java program for consuming data from partitioned kafka topic and runs workloads on stream processing cluster. In the program, there is a set of common APIs for stream processing which could be engined by stream processing systems. Currently we support these APIs on three stream processing systems: Storm, Flink and Spark Streaming. Several workloads are implemented by these common APIs. In StreamBench we implemented three workloads to benchmark performance of stream processing systems in different aspects. The architecture of StreamBench is shown in Figure~\ref{fig:streambench_architecture}. 

Except the core Java program, the architecture also includes three more components: Cluster Deploy, Data Generator and Statistic. Section ~\ref{chapter:environment_setup} describes how to use cluster deploy scripts to setup experiment environment. Data generators generate test data for workloads and send it to kafka cluster that is demonstrated detailedly in Section~\ref{section:data_generator}. The Statistic component discussed in Section~\ref{section:log_statistic} includes experiment logging and performance statistic. 

\section{Experiment Environment Setup}
\label{chapter:environment_setup}

The operator system running on experiment nodes is Ubuntu 14.04 LTS. Benchmarked stream processing systems are Spark-1.5.1, Storm-0.10.0 and Flink-0.10.1. To enable checkpoint feature of Spark, Hadoop2.6(HDFS) is installed in compute cluster. Kafka 0.8.2.1 is running as distribute message system here. 

To deploy these software in compute cluster and kafka cluster automatically, we developed a set of python script. The prerequisites of using these scripts include internet access, ssh passwordless login between nodes in cluster and cluster configuration that describes which nodes are compute node or kafka node and where is the master node. The basic logic of deploy scripts is to download softwares online and install them, then replace configure files which are contained in a Github repository. For detail information of how to use cluster deploy scripts and configure of Storm, Flink, Spark and Kafka, please check this Github repository~\footnote{\url{https://github.com/wangyangjun/StreamBench}}.

\section{Workloads}
\label{section:workloads}

In StreamBench, a workload consists of a stream processing application and one or more kafka topics. The application consumes messages from kafka cluster and executes operations or transformations on the messages. We have developed 3 workloads to evaluate different aspects of a system's performance. Each workload contains a representative operation or feature of stream processing system that can be used to evaluate systems at one particular point in the performance space. We have not attempted to exhaustively examine the entire performance space. As StreamBench is open sourced, users could also defined their own workloads either by defining a new set of workload parameters, or if necessary by implement a new workload which is discussed detailedly in section~\ref{section:extensibility}.


\subsection{Basic Operators}

With the widespread use of computer technologies, there is increasing demand of processing unbounded, continuous input streams. In most cases, only basic operations need to be performed on the data streams such as \texttt{map}, \texttt{reduce}. One good sample is stream WordCount. WordCount is a very common sample application of Hadoop MapReduce that counts the number of occurrences of each word in a given input set.\cite{MapReduce} Similarly, many stream processing systems also support it as an sample application to count words in a  given input stream. Stream WordCount is implemented with basic operations which are supported by almost all stream processing systems. It means either the system has such operations by default or the operations could be implemented with provided built-in APIs. Other basic operations include \texttt{flatMap}, \texttt{mapToPair} and \texttt{filter} which are similar to \texttt{map} and could be implemented by specializing \texttt{map} if not supported by default. In StreamBench, there are a set of corresponding basic APIs defined. The pseudocode of WordCount implemented with these basic APIs could be abstracted as Algorithm~\ref{alg:word_count}.

\begin{algorithm}
\caption{WordCount}\label{euclid}
\label{alg:word_count}
\begin{algorithmic}[1]
\State $\textit{sentenceStream.flatMap(...)}$
\State \hspace{2.6cm} $\textit{.mapToPair(...)}$
\State \hspace{2.6cm} $\textit{.reduceByKey(...)}$
\State \hspace{2.6cm} $\textit{.updateStateByKey(...)}$

\end{algorithmic}
\end{algorithm}

One special case of the basic APIs is \texttt{updateStateByKey}. Only in Spark Streaming there is a corresponding built-in operation. As discussed in Section~\ref{section:spark}, the computing model of Spark Streaming is micro-batch which is different with that of other stream processing systems. The results of operation \texttt{reduceByKey} of WordCount running in Spark Streaming is word counts of one single micro batch data set. Operation \texttt{updateStateByKey} is used to accumulate word counts in Spark Streaming. Because the model of Flink and Storm is stream processing and accumulated word counts are returned from \texttt{reduceByKey} directly. Therefore, when implementing the API \texttt{updateStateByKey} with Flink and Storm engine, nothing need to do. The goal of this workload is to evaluate the performance of stream processing systems executing basic operations.  


\subsection{Join Operator}
 \label{sub:join_operator}

Besides the cases in which only basic operations are performed, another typical type of stream use case is processing joins over unbounded streams. For example, in a surveillance application, we may want to correlate cell phone traffic with email traffic. Theoretically unbounded memory is required to processing join over unbounded input streams, since every record in one infinite stream must be compared with every record in the other. Obviously, this is not practical.\cite{window-join} Since the memory of a machine is limited, we need restrict the number of records stored for each stream with a time window. 

A window join takes two key-value pair streams of tuple, say stream \textit{S1:} \texttt{(k, v1)} and stream \textit{S2:} \texttt{(k, v2)}, along with window sizes for both \textit{S1} and \textit{S2} as input. The output is a stream of tuple \texttt{(k, v1, v2)}. Assuming a sliding window join between stream \textit{S1} and stream \textit{S2}, a new tuple arrival from stream \textit{S1}, then a summary of steps to preform join is the following:

\begin{enumerate}
\item Scan window of stream \textit{S2} to find any tuple which has the same key with this new tuple and propagate the result;
\item 
\begin{enumerate}
\item Insert the new tuple into stream \textit{S1}'s window or
\item  invalidate target tuple in stream \textit{S2}'s window if found;
\end{enumerate}
\item Invalidate all expired tuples in stream \textit{S1}'s window.
\end{enumerate}

\begin{figure}
  \begin{center}
  \subfigure{\includegraphics[scale=0.6]{images/join}}
   \caption{Window join scenario}
   \label{fig:window_join}
  \end{center}
\end{figure}

In step 2, there are two options. In the case of at most one tuple which has the same key with the new tuple could be found in stream \textit{S2}, option (b) is executed. Otherwise, option (a) is performed. Every time new tuple arrives stream \textit{S1}, window of stream \textit{S2} need be scanned. That reduces the performance of join operator, especially when the window is big.

In the first case mentioned above, with a data structure named \texttt{cachedHashTable} there is another way to implement stream join. The tuples in the window of a stream are stored in a cached hash table. Each tuple is cached for window time and expired tuples are invalidated automatically. One of such a \texttt{cachedHashTable} could be found in Guava.\footnote{\url{http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/cache/CacheBuilder.html}} Instead of scanning window of stream \textit{S2}, we could find tuple with the same key in \textit{S2} directly by calling \texttt{cachedHashTable.get(k)}. In theory, this implementation achieves better performance. 

Since Spark Streaming doesn't process tuples in a stream one by one, the join operator in Spark Streaming has different behaviours. In each batch interval, the RDD generated by stream1 will be joined with the RDD generated by stream2. For windowed streams, as long as slide durations of two windowed streams are the same, in each slide duration, the RDDs generated by two windowed streams will be joined. Because of this, window join in Spark Streaming could only make sure that a tuple in one stream will always be joined with corresponding tuple in the other stream that arrived earlier up to a configureable window time. Otherwise, repeat joined tuples would exist in generated RDDs of joined stream. As Figure~\ref{fig:spark_join_norepeat} shown, a tuple in Stream2 could be always joined with a corresponding tuple in Stream1 that arrived up to 2 seconds earlier. Since the slide duration of Stream2 is equal to its window size, no repeat joined tuple exists. On the other hand, it is possible that a tuple arrives earlier from Stream2 than the corresponding tuple in Stream1 couldn't be joined. Figure~\ref{fig:spark_join_repeat} exemplifies that there are tuples joined repeatedly  when slide duration of Stream2 is not equal to its window size.

\begin{figure}
  \begin{center}
  \subfigure{\includegraphics[scale=0.6]{images/spark_join_norepeat}}
   \caption{Spark Stream join without repeated tuple}
   \label{fig:spark_join_norepeat}
  \end{center}
\end{figure}


To evaluate performance of join operator in stream processing systems, we designed a workload called AdvClick which joins two streams in a online advertisement system. Every second there are a huge number of web pages opened which contain advertisement slots. A corresponding stream of shown advertisements is generated in the system and a record in the stream could be simply described as a tuple of \texttt{(id, shown time)}. Some of advertisements would be clicked by users and clicked advertisements is a stream which could be abstracted as a unbound tuples of \texttt{(id, clicked time)}. We assume that a record of advertisement shown always arrivers earlier than corresponding click record. Normally, if an advertisement is attractive to a user, it will be clicked in seconds or a few minutes after shown. We call such a click of an attractive advertisement valid click. To bill a customer, we need count all valid clicks regularly for advertisements of this customer. Which could be counted after joining stream \texttt{advertisement clicks} and stream \texttt{shown advertisements} with a configureable window time. 

\begin{figure}
  \begin{center}
  \subfigure{\includegraphics[scale=0.6]{images/spark_join_repeat}}
   \caption{Spark Stream join with repeated tuples}
   \label{fig:spark_join_repeat}
  \end{center}
\end{figure}

\subsection{Iterate Operator}

Iterative algorithms occur in many domains of data analysis, such as machine learning or graph analysis. Many stream data processing tasks require iterative sub-computations as well. To achieve these requirements, a data processing system should have the capacity to perform iterative processing on a real-time data stream. To achieve iterative sub-computations,  low-latency interactive access to results and consistent intermediate outputs, \citeauthor{murray2013naiad} introduced a computational model named timely dataflow that is based on a directed graph in which stateful vertices send and receive logically timestamped messages along directed edges. \cite{murray2013naiad} The dataflow graph may contain nested cycles and the timestamps reflect this structure in order to distinguish data that arise in different input epochs and loop iterations. With iterate operator, many stream processing systems already support such nested cycles in processing data flow graph. We designed a workload named StreamKMeans to evaluate iterate operator in stream processing systems.

KMeans is a clustering algorithm which aims to partition n points into k clusters in which each point belongs to the cluster with the nearest mean, serving as a prototype of the cluster.\cite{kmeans_wiki} Given an initial set of k means, the algorithm proceeds by alternating between two steps: \cite{mackay2003information}
\begin{description}
\item\textbf{Assignment step:} assign each point to the cluster whose mean yields the least within-cluster sum of squares.
\item \textbf{Update step:} Calculate the new means to be the centroids of the points in the new clusters.
\end{description}

The algorithm has converged when the assignments no longer change. We apply k-means algorithm on a stream of points with an iterate operator to update centroids.

Compared to clustering for data set, the clustering problem for the data stream domain is difficult because of two issues that are hard to address: (1) The quality of the clusters is poor when the data evolves considerably over time. (2) A data stream clustering algorithm requires much greater functionality in discovering and exploring clusters over different portions of the stream.\cite{aggarwal2003framework} Considering the main purpose of this workload is to evaluate iterative loop in stream data processing, we don't try to solve these issues here. Similarly, stream k-means also has two steps: assignment and update. The difference is each point in the stream only passes the application once and the application doesn't try to buffer points. As shown in Figure~\ref{fig:iterator_operator}, once a new centroid calculated, it will be broadcasted to assignment executors. 

 \begin{figure}
  \begin{center}
  \subfigure{\includegraphics[scale=0.6]{images/iterator_operator}}
   \caption{Stream k-means scenario}
   \label{fig:iterator_operator}
  \end{center}
\end{figure}

Spark executes data analysis pipeline using directed acyclic graph scheduler.  Nested cycle doesn't exist in the data pipeline graph. Therefore, this workload will not be used to benchmark Spark Streaming. Instead, a standalone version of k-means application is used to evaluate the performance of Spark Streaming.

\section{Data Generators}
\label{section:data_generator}
 A data generator is a program that produces and sends unbound records continuously to kafka cluster which are consumed by corresponding workload. For each workload, we designed one or several data generators with some parameters configureable which define the skew in record popularity, the size of records etc. These parameters could be changed to evaluate the performance of a system executing one workload on similar data streams with different properties. 

\subsection{WordCount}
\label{subsection:wordcount_generator}

Generators of workload WordCount produce unbound lists of sentences, each sentence consists of several words. The number of words in each sentence satisfies normal distribution with mean and variance configureable. Each word is a 5-digit zero-padded string of a binary integer, such as ``00001". There are two generators implemented with these integers satisfy two different distribution: uniform distribution and normal distribution.

\subsection{AdvClick}

As discussed in Section~\ref{sub:join_operator}, workload AdvClick joins stream \texttt{shown advertisements} and stream \texttt{advertisement clicks}. Each shown advertisement is a tuple consist of a universally unique identifier(\textbf{UUID}) and a timestamp. Each advertisement has a probability to be clicked. Then the data generator could be a multi-threads application with main thread producing advertisements and sub-threads producing clicks. The pseudocode of the main thread is shown as Algorithm \ref{alg:advclick_generator}. After a sub-thread starts, it sleeps for dalta time and then sends click record to corresponding kafka topic. 

\begin{algorithm}
\caption{AdvClick data generator}\label{euclid}
\label{alg:advclick_generator}
\begin{algorithmic}[1]
\State $\text{load } \textit{clickProbability} \text{ from configure file}$

\State $\textit{cachedThreadPool} \gets \text{new CachedThreadPool}$
\State $\textit{dataGenerator} \gets \text{new RandomDataGenerator}$ 
\State $\textit{producer} \gets \text{new KafkaProducer}$ 

\While{not interrupted}
\State $\textit{advId} \gets \text{new UUID}$ 
\State $\textit{timestamp} \gets \text{current timestamp}$ 
\State $\textit{producer.send(...)}$ 

\If {$\textit{generator.nextUniform(0,1)} < clickProbability$} 
\State $\textit{deltaTime} \gets \textit{generator.nextGaussian(...)}$ 
\State $\textit{cachedPool.submit(new ClickThread(advId, daltaTime))} $ 
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\subsection{KMeans}

Stream k-means is a one-pass clustering algorithm for stream data. In this workload, it is used to cluster a unbound stream of points. First, a set of centroids are generated and wrote to a external file. Then the generator produces points according these centroids as Algorithm~\ref{alg:kmeans_generator}.

\begin{algorithm}
\caption{KMeans data generator}\label{euclid}
\label{alg:kmeans_generator}
\begin{algorithmic}[1]
\State $\text{load } \textit{covariances} \text{ from configure file}$
\State $\textit{means} \gets \text{original point}$
\State $\text{load } \textit{centroids} \text{ from external file}$

\State $\textit{producer} \gets \text{new KafkaProducer}$ 
\State $\textit{normalDistributon } \gets \text{ new NormalDistribution(means, converiances)}$

\While{not interrupted}
\State $\textit{centroid} \gets \text{pick a centroid from \textit{centroids} randomly}$ 
\State $\textit{point} \gets \textit{centroid+normalDistributon.sample()}$ 
\State $\textit{producer.send(point)}$ 

\EndWhile
\end{algorithmic}
\end{algorithm}


\section{Experiment Logging and Statistic}
\label{section:log_statistic}

For evaluating the performance, there are two performance measurement terms used in StreamBench that are latency and throughput. Latency is the required time from a record entering the system to some results produced after some actions performed on the record. In StreamBench, messaging system and stream processing system are combined together and treated as one single system. The latency is computed start from when a record is generated. As discussed in Section \ref{section:data_generator}, data is sent to kafka cluster immediately after generation. Figure~\ref{fig:latency} shows how latency computed in StreamBench. 

Throughput is the number of actions executed or results produced per unit of time. In the WordCount workload, throughput is computed as the number of words counted per seconds in the whole compute cluster. Joined clicked stream and the number of points processed per second are the throughput of workloads AdvClick and Stream KMeans respectively.

There is an inherent tradeoff between latency and throughput: on a given hardware setup, as the amount of load increases by increase the speed of data generation, the latency of individual records increases as well since there is more contention for disk, CPU, network, and so on. Computing latency start from records generated makes it easy to measure the highest throughput, since records couldn't produced in time will stay in kafka topics that increase latency dramatically. A stream processing system with better performance will achieve low latency and high throughput with fewer servers.

\begin{figure}
  \begin{center}
  \subfigure{\includegraphics[scale=0.5]{images/latency}}
   \caption{Latency}
   \label{fig:latency}
  \end{center}
\end{figure}

\section{Extensibility}
\label{section:extensibility}

One significant feature of StreamBench is extensibility. The component "Workloads" in Figure~\ref{fig:streambench_architecture} contains three predefined workloads discussed in Section~\ref{section:workloads} that are implemented with common stream processing APIs. First, with some configuration modification of a data generator, which allows user to vary the skew in record popularity, and the size and number of records. The performances of a workload processing data streams with different properties could be different a lot. Moreover, it is easy for developers to design and implement a new workload to benchmark some specific features of stream processing systems. This approach allows for introducing more complex stream processing logic, and exploring tradeoffs of new stream processing features; but involves greater effort compared to the former approach.

Besides implementing new workloads, StreamBench also could be extended to benchmark new stream processing systems by implement a set of common stream processing APIs. A few samples of APIs could be shown as following:
\begin{itemize}
\item \textbf{map}(MapFunction\textless \textbf{T}, \textbf{R}\textgreater fun, String componentId): map each record in a stream from type \textbf{T} to type \textbf{R}
\item \textbf{mapToPair}(MapPairFunction\textless \textbf{T, K, V}\textgreater fun, String componentId): map a  item stream\textbf{\textless T\textgreater } to a pair stream\textbf{\textless K, V\textgreater}
\item \textbf{reduceByKey}(ReduceFunction\textless \textbf{V}\textgreater fun, String componentId): called on a pair stream of (\textbf{K, V}) pairs, return a new pair stream of (\textbf{K, V}) pairs where the values for each key are aggregated using the given reduce function
\end{itemize}

These methods are quite simple, representing common data transformations. There are some other APIs like \texttt{filter()}, \texttt{flatMap()} and \texttt{join} which are also easily to implement and supported well by most stream processing systems. Despite its simplicity, this API maps well to the native APIs of many of the stream processing systems we examined.





