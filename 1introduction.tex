\chapter{Introduction}
\label{chapter:intro}

Along with the rapid development of information technology, the speed of data generation increases dramatically. To process and analysis such large amount of data, the so-called Big Data,  cloud computing technologies get a quick development,  especially after these two papers related to MapReduce and BigTable published by Google  \cite{chang2006bigtable, dean2008mapreduce}.

In theory, Big Data doesn't only mean "big" \textbf{v}olume. Besides volume, Big Data still have two other properties: \textbf{v}elocity and \textbf{v}ariety \cite{doug2001data}. Velocity means the amount of data is growing at high speed. Variety refers to the various data formats. They are called three \textbf{\textit{V}}s of Big Data.  When deal with Big Data, there are two types of processing models to handle different kinds of data, batch processing and stream processing. Masses of structured and semi-structured historical data (\textbf{V}olume + \textbf{V}ariety) such as the Internet Archive of Wikipedia that are usually stored in distribute file systems and processed with batch processing technologies. On the other side, stream processing is used for fast data requirements (\textbf{V}elocity + \textbf{V}ariety)\cite{GameChanger}. Some fast data streams such as twitter stream, bank transactions and web page clicks are generated continuously in daily life.

Batch processing is generally more concerned with throughput than latency of individual components of the computation. In batch processing, data is collected and stored in file system. When the size of data reaches a threshold, batch jobs could be configured to run without manual intervention, executing against entire dataset at scale in order to produce output in the form of computational analyses and data files. Because of time consume in data collection and processing stage, depending on the size of the data being processed and the computational power of the system, output can be delayed significantly.

Stream processing is required for many practical cases which need analysed results from streaming data in a very short latency. Stock exchanges, sensor networks and user behaviour online analysis need to deal with high volume streams of real-time data. For example, a online shopping website would want give a customer accurate recommendations as soon as possible after the customer scans the website for a while. By analysing online transaction data stream, credit card fraud could be detected. Several stream processing systems are implemented and widely adopted, such as Apache Storm, Apache Spark, IBM InfoSphere Streams and Apache Flink. They all support high scalable, real-time stream processing and fault detection. 

Industry standard benchmark is a common and widely accepted way to evaluate a set of similar systems. Benchmarks enable rapid advancements in a field by having a standard reference for performance, and focus the attention of the research community on a common important task\cite{patterson2012better}. For example, TPC benchmarks such as TPC-C\cite{TPC-C}, TPC-H\cite{TPC-H}  have promoted the development of database systems. TPC-C simulates a complete computing environment where a population of users executes transactions against a database. TPC-H gives a standard evaluation of measuring the performance of highly-complex decision support databases.

How to evaluate a real time stream processing system before choosing it to use in production development is a open question.  Before these real time stream processing systems are implemented, \citeauthor{8requirements} demonstrated the 8 requirements\cite{8requirements} of real-time stream processing, which gives us a standard to evaluate whether a real time stream processing system satisfies these requirements.
%Current status of evaluating performance of stream processing system
Although some previous works\cite{cordovaanalysis, xinhstechblog, samza-benchmark, manoj-sotrm-vs-spark,flink-latency} are done to evaluate a stream processing system or compare the performance of several systems, they check performance through system specific applications. There is no such a benchmark tool that evaluates stream processing systems with a common set of workloads. In this thesis, we introduce a benchmark framework called StreamBench to facilitate performance comparisons of stream processing systems. The extensibility property of StreamBench allows us to add more workloads or benchmark new stream processing systems.

The main topic of this thesis is stream processing systems benchmark. First, cloud computing and benchmark technology background is introduced in Chapter 2. Chapter 3 presents architecture and main features of three widely used stream processing systems: Storm, Flink and Spark Streaming. In Chapter 4, we demonstrate the design of our benchmark framework -- StreamBench, including the whole architecture, test data generator and extensibility of StreamBench. Experiments and results are discussed in Chapter 5. At last, conclusions are given in Chapter 6.

\clearpage